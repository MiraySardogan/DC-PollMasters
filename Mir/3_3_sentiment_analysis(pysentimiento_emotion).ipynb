{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter, DayLocator\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Raisul\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Raisul\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the tweets file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>created_at</th>\n",
       "      <th>tweet</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>country</th>\n",
       "      <th>continent</th>\n",
       "      <th>state</th>\n",
       "      <th>candidate</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>detected_language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-10-15 00:00:02</td>\n",
       "      <td>#Trump: As a student I used to hear for years,...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>US</td>\n",
       "      <td>North America</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>trump_df</td>\n",
       "      <td>trump as a student i used to hear for years fo...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-10-15 00:00:08</td>\n",
       "      <td>You get a tie! And you get a tie! #Trump ‘s ra...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>US</td>\n",
       "      <td>North America</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>trump_df</td>\n",
       "      <td>you get a tie and you get a tie trump s rally ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>2020-10-15 00:00:17</td>\n",
       "      <td>@CLady62 Her 15 minutes were over long time ag...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>US</td>\n",
       "      <td>North America</td>\n",
       "      <td>California</td>\n",
       "      <td>trump_df</td>\n",
       "      <td>her 15 minutes were over long time ago omarosa...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>2020-10-15 00:00:18</td>\n",
       "      <td>@DeeviousDenise @realDonaldTrump @nypost There...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>US</td>\n",
       "      <td>North America</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>trump_df</td>\n",
       "      <td>there wont be many of them unless you all have...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>2020-10-15 00:00:20</td>\n",
       "      <td>One of the single most effective remedies to e...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>US</td>\n",
       "      <td>North America</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>trump_df</td>\n",
       "      <td>one of the single most effective remedies to e...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0           created_at  \\\n",
       "0           2  2020-10-15 00:00:02   \n",
       "1           4  2020-10-15 00:00:08   \n",
       "2           5  2020-10-15 00:00:17   \n",
       "3           7  2020-10-15 00:00:18   \n",
       "4           8  2020-10-15 00:00:20   \n",
       "\n",
       "                                               tweet  likes  retweet_count  \\\n",
       "0  #Trump: As a student I used to hear for years,...    2.0            1.0   \n",
       "1  You get a tie! And you get a tie! #Trump ‘s ra...    4.0            3.0   \n",
       "2  @CLady62 Her 15 minutes were over long time ag...    2.0            0.0   \n",
       "3  @DeeviousDenise @realDonaldTrump @nypost There...    0.0            0.0   \n",
       "4  One of the single most effective remedies to e...    0.0            0.0   \n",
       "\n",
       "  country      continent                 state candidate  \\\n",
       "0      US  North America                Oregon  trump_df   \n",
       "1      US  North America  District of Columbia  trump_df   \n",
       "2      US  North America            California  trump_df   \n",
       "3      US  North America                  Ohio  trump_df   \n",
       "4      US  North America          Pennsylvania  trump_df   \n",
       "\n",
       "                                       cleaned_tweet detected_language  \n",
       "0  trump as a student i used to hear for years fo...                en  \n",
       "1  you get a tie and you get a tie trump s rally ...                en  \n",
       "2  her 15 minutes were over long time ago omarosa...                en  \n",
       "3  there wont be many of them unless you all have...                en  \n",
       "4  one of the single most effective remedies to e...                en  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df= pd.read_csv(\"english_tweets.csv\")\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "stp_words= stopwords.words('english')\n",
    "print(stp_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First create a function to remove the stop words from the cleaned tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TweetFurtherCleaning(tweet):\n",
    "    cleanTweet= ' '.join(word for word in tweet.split() if word not in stp_words)\n",
    "    return cleanTweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df[\"cleaned_tweet\"]= tweets_df[\"cleaned_tweet\"].apply(TweetFurtherCleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>created_at</th>\n",
       "      <th>tweet</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>country</th>\n",
       "      <th>continent</th>\n",
       "      <th>state</th>\n",
       "      <th>candidate</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>detected_language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-10-15 00:00:02</td>\n",
       "      <td>#Trump: As a student I used to hear for years,...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>US</td>\n",
       "      <td>North America</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>trump_df</td>\n",
       "      <td>trump student used hear years ten years heard ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-10-15 00:00:08</td>\n",
       "      <td>You get a tie! And you get a tie! #Trump ‘s ra...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>US</td>\n",
       "      <td>North America</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>trump_df</td>\n",
       "      <td>get tie get tie trump rally iowa</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>2020-10-15 00:00:17</td>\n",
       "      <td>@CLady62 Her 15 minutes were over long time ag...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>US</td>\n",
       "      <td>North America</td>\n",
       "      <td>California</td>\n",
       "      <td>trump_df</td>\n",
       "      <td>15 minutes long time ago omarosa never represe...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>2020-10-15 00:00:18</td>\n",
       "      <td>@DeeviousDenise @realDonaldTrump @nypost There...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>US</td>\n",
       "      <td>North America</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>trump_df</td>\n",
       "      <td>wont many unless voting god prevails bo corrup...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>2020-10-15 00:00:20</td>\n",
       "      <td>One of the single most effective remedies to e...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>US</td>\n",
       "      <td>North America</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>trump_df</td>\n",
       "      <td>one single effective remedies eradicate anothe...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0           created_at  \\\n",
       "0           2  2020-10-15 00:00:02   \n",
       "1           4  2020-10-15 00:00:08   \n",
       "2           5  2020-10-15 00:00:17   \n",
       "3           7  2020-10-15 00:00:18   \n",
       "4           8  2020-10-15 00:00:20   \n",
       "\n",
       "                                               tweet  likes  retweet_count  \\\n",
       "0  #Trump: As a student I used to hear for years,...    2.0            1.0   \n",
       "1  You get a tie! And you get a tie! #Trump ‘s ra...    4.0            3.0   \n",
       "2  @CLady62 Her 15 minutes were over long time ag...    2.0            0.0   \n",
       "3  @DeeviousDenise @realDonaldTrump @nypost There...    0.0            0.0   \n",
       "4  One of the single most effective remedies to e...    0.0            0.0   \n",
       "\n",
       "  country      continent                 state candidate  \\\n",
       "0      US  North America                Oregon  trump_df   \n",
       "1      US  North America  District of Columbia  trump_df   \n",
       "2      US  North America            California  trump_df   \n",
       "3      US  North America                  Ohio  trump_df   \n",
       "4      US  North America          Pennsylvania  trump_df   \n",
       "\n",
       "                                       cleaned_tweet detected_language  \n",
       "0  trump student used hear years ten years heard ...                en  \n",
       "1                   get tie get tie trump rally iowa                en  \n",
       "2  15 minutes long time ago omarosa never represe...                en  \n",
       "3  wont many unless voting god prevails bo corrup...                en  \n",
       "4  one single effective remedies eradicate anothe...                en  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(293929, 11)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Emotion analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7ea788d20e14ea893f58c019bf33556",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/999 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Raisul\\Anaconda3\\envs\\my_env\\Lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Raisul\\.cache\\huggingface\\hub\\models--finiteautomata--bertweet-base-emotion-analysis. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fa1289cf4c5413a93ba193f93a2de3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/540M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6301da0fb2cc404a8adcf8abe1b267c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/295 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69bff300b07a44898d87d8faee179a26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/843k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e474772dc6db4ad2aa0495b5214601e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "bpe.codes:   0%|          | 0.00/1.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ea9063f6b7d49b9b8bd66fc67bb954c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/17.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc633c6e20d44924b29656b84db00f16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pysentimiento import create_analyzer\n",
    "import transformers\n",
    "\n",
    "transformers.logging.set_verbosity(transformers.logging.ERROR)\n",
    "\n",
    "analyzer = create_analyzer(task=\"emotion\", lang=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment(input_text):\n",
    "    sentiment_result= analyzer.predict(input_text)\n",
    "    return sentiment_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "result= tweets_df[\"cleaned_tweet\"].apply(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         AnalyzerOutput(output=others, probas={others: ...\n",
       "1         AnalyzerOutput(output=others, probas={others: ...\n",
       "2         AnalyzerOutput(output=others, probas={others: ...\n",
       "3         AnalyzerOutput(output=others, probas={others: ...\n",
       "4         AnalyzerOutput(output=others, probas={others: ...\n",
       "                                ...                        \n",
       "293924    AnalyzerOutput(output=others, probas={others: ...\n",
       "293925    AnalyzerOutput(output=disgust, probas={disgust...\n",
       "293926    AnalyzerOutput(output=joy, probas={joy: 0.795,...\n",
       "293927    AnalyzerOutput(output=disgust, probas={disgust...\n",
       "293928    AnalyzerOutput(output=others, probas={others: ...\n",
       "Name: cleaned_tweet, Length: 293929, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df= pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.rename(columns={\"cleaned_tweet\": \"sentiment\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AnalyzerOutput(output=others, probas={others: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AnalyzerOutput(output=others, probas={others: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AnalyzerOutput(output=others, probas={others: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AnalyzerOutput(output=others, probas={others: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AnalyzerOutput(output=others, probas={others: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293924</th>\n",
       "      <td>AnalyzerOutput(output=others, probas={others: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293925</th>\n",
       "      <td>AnalyzerOutput(output=disgust, probas={disgust...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293926</th>\n",
       "      <td>AnalyzerOutput(output=joy, probas={joy: 0.795,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293927</th>\n",
       "      <td>AnalyzerOutput(output=disgust, probas={disgust...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293928</th>\n",
       "      <td>AnalyzerOutput(output=others, probas={others: ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>293929 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentiment\n",
       "0       AnalyzerOutput(output=others, probas={others: ...\n",
       "1       AnalyzerOutput(output=others, probas={others: ...\n",
       "2       AnalyzerOutput(output=others, probas={others: ...\n",
       "3       AnalyzerOutput(output=others, probas={others: ...\n",
       "4       AnalyzerOutput(output=others, probas={others: ...\n",
       "...                                                   ...\n",
       "293924  AnalyzerOutput(output=others, probas={others: ...\n",
       "293925  AnalyzerOutput(output=disgust, probas={disgust...\n",
       "293926  AnalyzerOutput(output=joy, probas={joy: 0.795,...\n",
       "293927  AnalyzerOutput(output=disgust, probas={disgust...\n",
       "293928  AnalyzerOutput(output=others, probas={others: ...\n",
       "\n",
       "[293929 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(\"pysentimiento_emotion.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
